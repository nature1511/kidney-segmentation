{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_15524\\4064904260.py:3: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n",
            "c:\\Users\\123\\Desktop\\human vasculature\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from segmentation.config import CFG\n",
        "from segmentation.models.unet import unet\n",
        "from segmentation.scr.utils import losses, transforms\n",
        "from segmentation.scr.utils.utils import set_seed, save_model\n",
        "from segmentation.scr.tilling_dataset import Tilling_Dataset\n",
        "from segmentation.scr.train_function import train_model\n",
        "from segmentation.scr.utils.metrics import dice_coef\n",
        "\n",
        "from colorama import Fore, Style\n",
        "c_  = Fore.GREEN\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "#from segmentation.scr\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_transform  = transforms.get_transform(transform_type='weak')\n",
        "val_transform = transforms.get_transform(transform_type='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset contains 20744 empty and 33952 non-empty tiles.\n",
            "Sample 2250 empty and 5250 non-empty tiles.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Tilling_Dataset(\n",
        "    name_data='kidney_1_tilling',\n",
        "    path_to_df=CFG.path_df_kidney_1_till,\n",
        "    use_random_sub=True,\n",
        "    empty_tile_pct=30,\n",
        "    sample_limit=7500,\n",
        "    random_seed=CFG.random_seed\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset contains 14595 empty and 6447 non-empty tiles.\n",
            "Sample 800 empty and 1200 non-empty tiles.\n"
          ]
        }
      ],
      "source": [
        "val_dataset = Tilling_Dataset(\n",
        "    name_data='kidney_3_tilling',\n",
        "    path_to_df=CFG.path_df_kidney_3_till,\n",
        "    use_random_sub=True,\n",
        "    empty_tile_pct=40,\n",
        "    sample_limit=2000,\n",
        "    random_seed=CFG.random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed(CFG.random_seed)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG.train_batch_size, num_workers=2, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(train_dataset, batch_size=CFG.valid_batch_size, num_workers=2, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = unet.UNet(n_channels=3, n_classes=1, bilinear=False).to(CFG.device)\n",
        "num_epoch = 30\n",
        "loss_fn = losses.BCE_DICE(mode=\"SUM\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4) \n",
        "sheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer, mode='max', patience=3, factor=0.6, verbose=True, threshold=1e-3)\n",
        "device = CFG.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train : 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 938/938 [57:56<00:00,  3.71s/it, epoch=938, gpu_mem=6.47 GB, lr=0.00030, train_loss=0.1354]\n",
            "Valid :   8%|\u258a         | 36/469 [00:32<06:16,  1.15it/s, gpu_memory=5.29 GB, valid_loss=0.7862]"
          ]
        }
      ],
      "source": [
        "train_model(model=model, \n",
        "                optimizer=optimizer, \n",
        "                loss_func=loss_fn, \n",
        "                train_loader=train_loader, \n",
        "                val_loader=val_loader, \n",
        "                num_epochs=num_epoch, \n",
        "                scheduler=sheduler, \n",
        "                device =CFG.device,\n",
        "                path_to_save=CFG.path_to_save_state_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
