{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\123\\Desktop\\human vasculature\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_22388\\3577123373.py:11: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn  \n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from torch.cuda.amp import autocast\n",
        "import cv2\n",
        "import os,sys\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.parallel import DataParallel\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.cuda import amp\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import gc\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from typing import Optional, TypeVar\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.parallel import DataParallel\n",
        "\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.cuda import amp\n",
        "\n",
        "\n",
        "#from segmentation.config import Configs as CFG\n",
        "from segmentation.models.unet import unet\n",
        "from segmentation.scr.utils import losses, metrics, set_seed, transforms, rle_coding\n",
        "from segmentation.scr.tilling_dataset import Tilling_Dataset\n",
        "from colorama import Fore, Back, Style\n",
        "c_  = Fore.GREEN\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "#from segmentation.scr\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CFG:\n",
        "\n",
        "    # configs for tilling dataset kidney 1\n",
        "    path_img_kidney1 = \"data\\\\train\\\\kidney_1_dense\\\\images\"\n",
        "    path_lb_kidney1 = \"data\\\\train\\\\kidney_1_dense\\\\labels\"\n",
        "    path_df_kidney_1_till = \"data\\\\kidney_1_tilling.csv\"\n",
        "    tile_size = (512, 512)\n",
        "    overlap_pct = 10\n",
        "    cache_dir = \"data\"\n",
        "\n",
        "    # configs for tilling dataset kidney 1\n",
        "    path_img_kidney3 = \"data\\\\train\\\\kidney_3_sparse\\\\images\"\n",
        "    path_lb_kidney3 = \"data\\\\train\\\\kidney_3_dense\\\\labels\"\n",
        "    path_df_kidney_3_till = \"data\\\\kidney_3_tilling.csv\"\n",
        "    tile_size = (512, 512)\n",
        "    overlap_pct = 10\n",
        "    cache_dir = \"data\"\n",
        "\n",
        "    # configs for transforms\n",
        "    p_rot = 0.3\n",
        "    p_aug = 0.3\n",
        "    # cofigs for train / eval model\n",
        "    random_seed = 42\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    train_batch_size = 4\n",
        "    n_accumulate = max(1, 32 // train_batch_size)\n",
        "    valid_batch_size = train_batch_size * 2\n",
        "    \n",
        "    max_norm_grad = 5\n",
        "\n",
        "    epochs = 28\n",
        "    lr = 3e-4\n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_transform  = transforms.get_transform(transform_type='weak')\n",
        "val_transform = transforms.get_transform(transform_type='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000\n",
            "Dataset contains 1528 empty and 12146 non-empty tiles.\n",
            "Sample 300 empty and 2700 non-empty tiles.\n",
            "50\n",
            "Dataset contains 3420 empty and 4596 non-empty tiles.\n",
            "Sample 5 empty and 45 non-empty tiles.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Tilling_Dataset(\n",
        "    name_data='kidney_1_tilling',\n",
        "    path_to_df=CFG.path_df_kidney_1_till,\n",
        "    use_random_sub=True,\n",
        "    empty_tile_pct=10,\n",
        "    sample_limit=3000\n",
        ")\n",
        "val_dataset = Tilling_Dataset(\n",
        "    name_data='kidney_1_tilling',\n",
        "    path_to_df=CFG.path_df_kidney_3_till,\n",
        "    use_random_sub=True,\n",
        "    empty_tile_pct=10,\n",
        "    sample_limit=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed.set_seed(42)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG.train_batch_size, num_workers=2, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(train_dataset, batch_size=CFG.valid_batch_size, num_workers=2, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = unet.UNet(n_channels=3, n_classes=1, bilinear=False).to(CFG.device)\n",
        "num_epoch = 4\n",
        "loss_fn = losses.BCE_DICE(mode=\"SUM\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-4)\n",
        "device = CFG.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_loop(model, optimizer, loss_func, train_loader, device, grad_clip = True):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    dataset_size = 0\n",
        "    optimizer.zero_grad()\n",
        "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc='Train ')\n",
        "    for step, batch in pbar:\n",
        "        images, masks,_, _ = batch\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        masks  = masks.to(device, dtype=torch.float)\n",
        "        \n",
        "        images = images / 255.\n",
        "        masks = masks / 255.\n",
        "        \n",
        "        batch_size = images.shape[0]\n",
        "        dataset_size += batch_size\n",
        "    \n",
        "        y_pred = model(images)\n",
        "            \n",
        "        loss   = loss_func(y_pred, masks)\n",
        "        loss   = loss / CFG.n_accumulate\n",
        "        loss.backward() #loss.backward()  # backward-pass\n",
        "\n",
        "        running_loss += loss.item() * batch_size\n",
        "        dataset_size += batch_size\n",
        "        del images\n",
        "        del masks\n",
        "        del y_pred\n",
        "        \n",
        "        if (step + 1) % CFG.n_accumulate == 0 or (step + 1 == len(train_loader)):\n",
        "            if grad_clip:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=CFG.max_norm_grad)\n",
        "            optimizer.step()  # update weights\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        pbar.set_postfix( epoch=f'{step + 1}',\n",
        "                          train_loss=f'{running_loss / dataset_size:0.4f}',\n",
        "                          #train_dice = f'{train_dice:0.4f}',\n",
        "                          #train_jaccard = f'{train_jaccard:0.4f}',\n",
        "                          lr=f'{current_lr:0.5f}',\n",
        "                          gpu_mem=f'{mem:0.2f} GB')\n",
        "    epoch_loss = running_loss / dataset_size\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return epoch_loss\n",
        "        \n",
        "            \n",
        "        \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train :   2%|\u258f         | 13/750 [04:09<3:56:12, 19.23s/it, epoch=13, gpu_mem=14.25 GB, lr=0.00030, train_loss=0.0960]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_one_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[8], line 26\u001b[0m, in \u001b[0;36mtrain_one_loop\u001b[1;34m(model, optimizer, loss_func, train_loader, device, grad_clip)\u001b[0m\n\u001b[0;32m     23\u001b[0m loss   \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m CFG\u001b[38;5;241m.\u001b[39mn_accumulate\n\u001b[0;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m#loss.backward()  # backward-pass\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[0;32m     27\u001b[0m dataset_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m images\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_one_loop(model=model,optimizer=optimizer, train_loader=train_loader,\n",
        "               loss_func=loss_fn, device=CFG.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2844"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images, masks,_, _ = next(iter(train_loader))\n",
        "images = images.to(CFG.device, dtype=torch.float)\n",
        "masks  = masks.to(CFG.device, dtype=torch.float)\n",
        "\n",
        "y_pred = model(images)\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch_usual(model, dataloader, loss_fn, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    scaler = amp.GradScaler()\n",
        "    epoch_loss = 0\n",
        "    running_loss = 0\n",
        "    train_loss = 0.0\n",
        "    dataset_size = 0\n",
        "    train_scores = []\n",
        "\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
        "    loss_batch = 0\n",
        "    for step, (images, masks) in pbar:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        masks  = masks.to(device, dtype=torch.float)\n",
        "        batch_size = images.size(0)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        with amp.autocast():\n",
        "            y_pred = model(images)\n",
        "            loss   = loss_fn(y_pred, masks)\n",
        "            loss   = loss / CFG.n_accumulate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward() #loss.backward()  # backward-pass\n",
        "\n",
        "        running_loss += loss.item() * batch_size\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        if (step + 1) % n_accumulate == 0 or (step + 1 == len(dataloader)):\n",
        "            scaler.step(optimizer) #optimizer.step()  # update weights\n",
        "            scaler.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #train_loss  += loss_batch  * batch_size * n_accumulate\n",
        "            #epoch_loss = train_loss / dataset_size\n",
        "            #loss_batch = 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        #y_pred = nn.Sigmoid()(y_pred)\n",
        "        #train_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
        "        #train_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
        "        #3train_scores.append([train_dice, train_jaccard])\n",
        "        #if (step + 1) % n_accumulate == 0 or (step + 1 == len(dataloader)):\n",
        "        pbar.set_postfix( epoch=f'{step}',\n",
        "                          #train_loss=f'{loss_batch / len(dataloader):0.4f}',\n",
        "                          #train_dice = f'{train_dice:0.4f}',\n",
        "                          #train_jaccard = f'{train_jaccard:0.4f}',\n",
        "                          lr=f'{current_lr:0.5f}',\n",
        "                          gpu_mem=f'{mem:0.2f} GB')\n",
        "\n",
        "\n",
        "    #train_scores  = np.mean(train_scores, axis=0)\n",
        "\n",
        "\n",
        "    del images\n",
        "    del masks\n",
        "    del y_pred\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    print(epoch_loss)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 25\n",
        "\n",
        "def train():\n",
        "    model = AttentionUNet()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_loader[2][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader[8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_path, lb_path, is_empty, bbx, px_stats, size = train_loader[8]\n",
        "\n",
        "\n",
        "\n",
        "fig, axarr = plt.subplots(ncols=3, figsize=(12, 6))\n",
        "axarr[0].imshow(torch.permute(img, (1,2,0)).numpy(), cmap=\"gray\")\n",
        "axarr[1].imshow(color.label2rgb(mask.numpy(), torch.permute(img, (1,2,0)).numpy(), bg_label=0, bg_color=(1.,1.,1.), alpha=0.25))\n",
        "axarr[2].imshow(mask, vmin=0, interpolation='antialiased', interpolation_stage='rgba')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
