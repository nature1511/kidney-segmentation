{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from segmentation.scr.utils.utils import set_seed\n",
        "from segmentation.scr.utils.metrics import dice_coef\n",
        "from segmentation.models.smp import get_pretrained_model\n",
        "from segmentation.config import CFG\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from segmentation.scr.inference.tta import tta\n",
        "\n",
        "from segmentation.scr.train_model.data_loader import *\n",
        "from segmentation.scr.utils.utils import set_seed, resize_to_size\n",
        "from segmentation.scr.train_model.evaluate_dataset import evaluate_dataset\n",
        "from segmentation.scr.inference import tta, create_tillings\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_my_pc= get_pretrained_model(path_to_model='weight\\mobnet_my_pc.pth', train_parallel=False, CFG=CFG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_img_dir=\"data\\\\train\\\\kidney_3_sparse\\\\images\"\n",
        "path_lb_dir=\"data\\\\train\\\\kidney_3_dense\\\\labels\"\n",
        "img_path, lb_path = create_img_lb_paths(path_img_dir = path_img_dir, path_lb_dir = path_lb_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Data_loader_inference(Dataset):\n",
        "    def __init__(self,img_path,lb_path):\n",
        "        self.img_paths=img_path\n",
        "        self.lb_path = lb_path\n",
        "        h_m, w_m = 0,0\n",
        "        for path in self.img_paths:\n",
        "            img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
        "            h, w  = img.shape\n",
        "            h_m = max(h, h_m)\n",
        "            w_m = max(w, w_m)\n",
        "        self.img_size = (h_m, w_m)\n",
        "        \n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.lb_path)- CFG.in_chans\n",
        "        #return len(self.paths)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        paths_img  = self.img_paths[index : index +  CFG.in_chans]\n",
        "        path_lb  = self.lb_path[index + CFG.in_chans // 2]\n",
        "        \n",
        "        images = []\n",
        "\n",
        "        for path_img in paths_img:\n",
        "            img=cv2.imread(path_img,cv2.IMREAD_GRAYSCALE)\n",
        "            h, w  = img.shape\n",
        "            img=torch.from_numpy(img).to(torch.uint8)\n",
        "            if h < self.img_size[0] or w < self.img_size[1]:\n",
        "                img = resize_to_size(img=img, image_size=self.img_size)\n",
        "            images.append(img)\n",
        "            \n",
        "        label = cv2.imread(path_lb,cv2.IMREAD_GRAYSCALE)\n",
        "        label=torch.from_numpy(label!=0).to(torch.uint8)*255\n",
        "        if h < self.img_size[0] or w < self.img_size[1]:  \n",
        "            label = resize_to_size(img=label, image_size=self.img_size)\n",
        "        images= torch.stack(images)\n",
        "      \n",
        "\n",
        "        return images, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader_inf = Data_loader_inference(img_path, lb_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_loader = DataLoader(loader_inf, batch_size=1, shuffle=False, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_images(model, loader, use_tta = False, overlap_pct = 10):\n",
        "    model.eval()\n",
        "    timer = tqdm(range(len(loader)))\n",
        "    val_scores = 0\n",
        "    scores = []\n",
        "    for i, (images, mask) in enumerate(loader):\n",
        "        tills, indexs = create_tillings.create_tillings(images=images, overlap_pct=overlap_pct )\n",
        "        till_shape = len(tills)\n",
        "        tills = torch.cat(tills)\n",
        "        tills =tills.to(torch.float32)\n",
        "        #tills  = filter_noise(tills)\n",
        "        tills = norm_with_clip(tills .reshape(-1, *tills.shape[2:])).reshape(tills.shape)\n",
        "        with torch.no_grad():\n",
        "            if not use_tta:\n",
        "                pred = model(tills.cuda().to(torch.float32))\n",
        "                pred = pred.cpu()\n",
        "                pred = pred.sigmoid()\n",
        "            else:\n",
        "                pred = tta.tta(model=model, x=tills.cuda().to(torch.float32))\n",
        "                pred = pred.cpu()\n",
        "        pred = pred.reshape(till_shape, CFG.input_size, CFG.input_size)\n",
        "        mask_pred = torch.zeros_like(mask,dtype=torch.float32)\n",
        "        mask_count = torch.zeros_like(mask,dtype=torch.float32)\n",
        "        \n",
        "        for j,(y1,y2,x1,x2) in enumerate(indexs):\n",
        "            mask_pred[...,y1:y2, x1:x2] += pred [j]\n",
        "            mask_count[...,y1:y2, x1:x2] += 1\n",
        " \n",
        "        mask_pred /= mask_count\n",
        "        #print(mask_pred.shape, mask.shape)\n",
        "        score = dice_coef(mask_pred.detach(), mask > 0, from_logits= False)\n",
        "        scores.append(score.detach().cpu().item())\n",
        "        val_scores = (val_scores * i + score.detach().cpu().item()) / (i + 1)\n",
        "       \n",
        "        timer.set_description(f\"eval--> score:{val_scores:.4f}\")\n",
        "        timer.update()\n",
        "        \n",
        "\n",
        "    timer.close()\n",
        "    return scores, val_scores\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_no, val_scores = predict_images(model = model_my_pc, loader = val_loader, use_tta = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy\n",
        "scipy.stats.ttest_rel(a=scores_yes, b=scores_no)#,alternative='greater')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.mean(scores_yes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.mean(scores_no)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, masks = batch\n",
        "images = (min_max_normalization(images.to(torch.float16)[None])[0]*255).to(torch.uint8)\n",
        "tills, indexs = create_tillings(images=images, overlap_pct=10)\n",
        "till_shape = len(tills)\n",
        "tills = torch.cat(tills)\n",
        "tills =tills.to(torch.float32)\n",
        "tills = norm_with_clip(tills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_my_pc.eval()\n",
        "with torch.no_grad():\n",
        "    ans= tta(model=model_my_pc, x=tills.cuda().to(torch.float32))\n",
        "ans = ans.cpu()\n",
        "#ans = ans.sigmoid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ans = ans.reshape(till_shape, 2, CFG.input_size, CFG.input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_pred = torch.zeros_like(masks,dtype=torch.float32)\n",
        "mask_count = torch.zeros_like(masks,dtype=torch.float32)\n",
        "for i,(y1,y2,x1,x2) in enumerate(indexs):\n",
        "    mask_pred[...,y1:y2, x1:x2] += ans[i]\n",
        "    mask_count[...,y1:y2, x1:x2] += 1\n",
        " \n",
        "mask_pred /= mask_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_coef(mask_pred[1], masks > 0, from_logits= False, thr=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy\n",
        "scipy.stats.ttest_rel(a=scores_my, b=scores_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
